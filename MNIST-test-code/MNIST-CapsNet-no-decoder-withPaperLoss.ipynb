{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setttings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c70938a3a011>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-applications/MNIST_data//train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../Tensorflow-applications/MNIST_data//train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../Tensorflow-applications/MNIST_data//t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Tensorflow-applications/MNIST_data//t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../../Tensorflow-applications/MNIST_data//\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(5000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images.shape)\n",
    "print(mnist.validation.images.shape)\n",
    "print(mnist.test.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[:,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "rounds = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_reshape = tf.reshape(X, [-1, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(input_vector, axis):\n",
    "    normalised_input = tf.reduce_sum(tf.square(input_vector), axis = axis, keepdims = True)\n",
    "    scale = tf.divide(normalised_input, tf.add(normalised_input, 1.))\n",
    "    vector = tf.divide(input_vector, tf.sqrt(tf.add(normalised_input, epsilon)))\n",
    "    output = tf.multiply(scale, vector)\n",
    "    \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter_shape = [9, 9, 1, 256]\n",
    "weights = tf.Variable(tf.truncated_normal(conv_filter_shape, stddev=0.3), name='W1')\n",
    "bias = tf.Variable(tf.truncated_normal([256], stddev=0.3), name='B1')\n",
    "out_layer = tf.nn.conv2d(X_reshape, weights, [1,1,1,1], padding = 'VALID')\n",
    "out_layer_bias = tf.add(out_layer, bias)\n",
    "layer1 = tf.nn.relu(out_layer_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PrimaryCaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filter_shape = [9, 9, 256, 256]\n",
    "weights = tf.Variable(tf.truncated_normal(conv_filter_shape, stddev=0.3), name='W2')\n",
    "bias = tf.Variable(tf.truncated_normal([256], stddev=0.3), name='B2')\n",
    "out_layer = tf.nn.conv2d(layer1, weights, [1,2,2,1], padding = 'VALID')\n",
    "layer2 = tf.add(out_layer, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_raw = tf.reshape(layer2, [-1, 6*6*32, 8], name='caps1_raw')\n",
    "caps1_output = squash(caps1_raw, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output_expand = tf.expand_dims(caps1_output, axis=-1)\n",
    "caps1_output_expand2 = tf.expand_dims(caps1_output_expand, axis=2)\n",
    "caps1_output_expand2_tiled = tf.tile(caps1_output_expand2, [1,1,10,1,1], name = 'caps1_out_tiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = tf.Variable(tf.truncated_normal([1, 1152, 10, 16, 8], stddev=0.1), name='W_matrix')\n",
    "batch = tf.shape(X)[0]\n",
    "weight_matrix_tiled = tf.tile(weight_matrix, [batch, 1, 1, 1, 1], name = 'W_matrix_tiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(weight_matrix_tiled, caps1_output_expand2_tiled, name='caps2_predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing by agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weights = tf.zeros([batch, 1152, 10, 1, 1], name = 'raw_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(rounds):\n",
    "    routing_weights = tf.nn.softmax(raw_weights, axis=2, name = 'routing_weights' + str(i))\n",
    "    weighted_predictions = tf.multiply(routing_weights, caps2_predicted, name = 'weighted_predictions' + str(i))\n",
    "    weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, name = 'weighted_sum' + str(i), keepdims = True)\n",
    "    caps2_output = squash(weighted_sum, axis=-2)\n",
    "    \n",
    "    caps2_output_tiled = tf.tile(caps2_output, [1, 1152, 1, 1, 1], name = 'caps2_output_tiled'+ str(i))\n",
    "    agreement = tf.matmul(caps2_predicted, caps2_output_tiled, transpose_a = True, name = 'agreement'+ str(i))\n",
    "    raw_weights = tf.add(raw_weights, agreement, name = 'raw_weights' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_norm_caps2 = tf.reduce_sum(tf.square(caps2_output), axis=-2, keepdims = False, name='caps2_norm')\n",
    "caps2_activation = tf.sqrt(tf.add(squared_norm_caps2, epsilon), name = 'caps2_activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_proba_max = tf.argmax(caps2_activation, axis=2, name = 'y_proba_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.squeeze(caps2_activation, axis=[1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_minus = 0.1\n",
    "m_plus = 0.9\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_norm_caps2_loss = tf.reduce_sum(tf.square(caps2_output), axis=-2, keepdims = True, name='caps2_norm_loss')\n",
    "caps2_activation_loss = tf.sqrt(tf.add(squared_norm_caps2, epsilon), name = 'caps2_activation_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_error_raw = tf.square(tf.maximum(0., tf.subtract(m_plus, caps2_activation_loss)), \n",
    "                              name = 'present_error_raw')\n",
    "present_error = tf.reshape(present_error_raw, shape = [-1, 10], name = 'present_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_error_raw = tf.square(tf.maximum(0., tf.subtract(caps2_activation_loss, m_minus)), \n",
    "                             name = 'absent_error_raw')\n",
    "absent_error = tf.reshape(absent_error_raw, shape=[-1,10], name = 'absent_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = tf.add(tf.multiply(y, present_error), tf.multiply(tf.multiply(lambda_, tf.subtract(1., y)), absent_error),\n",
    "          name = 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name = 'margin_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(margin_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,axis=1), tf.argmax(y_pred, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../my_capsule_network\n",
      "batch_iteration: 0\n",
      "batch_iteration: 1\n",
      "batch_iteration: 2\n",
      "batch_iteration: 3\n",
      "batch_iteration: 4\n",
      "batch_iteration: 5\n",
      "batch_iteration: 6\n",
      "batch_iteration: 7\n",
      "batch_iteration: 8\n",
      "batch_iteration: 9\n",
      "batch_iteration: 10\n",
      "batch_iteration: 11\n",
      "batch_iteration: 12\n",
      "batch_iteration: 13\n",
      "batch_iteration: 14\n",
      "batch_iteration: 15\n",
      "batch_iteration: 16\n",
      "batch_iteration: 17\n",
      "batch_iteration: 18\n",
      "batch_iteration: 19\n",
      "batch_iteration: 20\n",
      "batch_iteration: 21\n",
      "batch_iteration: 22\n",
      "batch_iteration: 23\n",
      "batch_iteration: 24\n",
      "batch_iteration: 25\n",
      "batch_iteration: 26\n",
      "batch_iteration: 27\n",
      "batch_iteration: 28\n",
      "batch_iteration: 29\n",
      "batch_iteration: 30\n",
      "batch_iteration: 31\n",
      "batch_iteration: 32\n",
      "batch_iteration: 33\n",
      "batch_iteration: 34\n",
      "batch_iteration: 35\n",
      "batch_iteration: 36\n",
      "batch_iteration: 37\n",
      "batch_iteration: 38\n",
      "batch_iteration: 39\n",
      "batch_iteration: 40\n",
      "batch_iteration: 41\n",
      "batch_iteration: 42\n",
      "batch_iteration: 43\n",
      "batch_iteration: 44\n",
      "batch_iteration: 45\n",
      "batch_iteration: 46\n",
      "batch_iteration: 47\n",
      "batch_iteration: 48\n",
      "batch_iteration: 49\n",
      "batch_iteration: 50\n",
      "batch_iteration: 51\n",
      "batch_iteration: 52\n",
      "batch_iteration: 53\n",
      "batch_iteration: 54\n",
      "batch_iteration: 55\n",
      "batch_iteration: 56\n",
      "batch_iteration: 57\n",
      "batch_iteration: 58\n",
      "batch_iteration: 59\n",
      "batch_iteration: 60\n",
      "batch_iteration: 61\n",
      "batch_iteration: 62\n",
      "batch_iteration: 63\n",
      "batch_iteration: 64\n",
      "batch_iteration: 65\n",
      "batch_iteration: 66\n",
      "batch_iteration: 67\n",
      "batch_iteration: 68\n",
      "batch_iteration: 69\n",
      "batch_iteration: 70\n",
      "batch_iteration: 71\n",
      "batch_iteration: 72\n",
      "batch_iteration: 73\n",
      "batch_iteration: 74\n",
      "batch_iteration: 75\n",
      "batch_iteration: 76\n",
      "batch_iteration: 77\n",
      "batch_iteration: 78\n",
      "batch_iteration: 79\n",
      "batch_iteration: 80\n",
      "batch_iteration: 81\n",
      "batch_iteration: 82\n",
      "batch_iteration: 83\n",
      "batch_iteration: 84\n",
      "batch_iteration: 85\n",
      "batch_iteration: 86\n",
      "batch_iteration: 87\n",
      "batch_iteration: 88\n",
      "batch_iteration: 89\n",
      "batch_iteration: 90\n",
      "batch_iteration: 91\n",
      "batch_iteration: 92\n",
      "batch_iteration: 93\n",
      "batch_iteration: 94\n",
      "batch_iteration: 95\n",
      "batch_iteration: 96\n",
      "batch_iteration: 97\n",
      "batch_iteration: 98\n",
      "batch_iteration: 99\n",
      "batch_iteration: 100\n",
      "batch_iteration: 101\n",
      "batch_iteration: 102\n",
      "batch_iteration: 103\n",
      "batch_iteration: 104\n",
      "batch_iteration: 105\n",
      "batch_iteration: 106\n",
      "batch_iteration: 107\n",
      "batch_iteration: 108\n",
      "batch_iteration: 109\n",
      "batch_iteration: 110\n",
      "batch_iteration: 111\n",
      "batch_iteration: 112\n",
      "batch_iteration: 113\n",
      "batch_iteration: 114\n",
      "batch_iteration: 115\n",
      "batch_iteration: 116\n",
      "batch_iteration: 117\n",
      "batch_iteration: 118\n",
      "batch_iteration: 119\n",
      "batch_iteration: 120\n",
      "batch_iteration: 121\n",
      "batch_iteration: 122\n",
      "batch_iteration: 123\n",
      "batch_iteration: 124\n",
      "batch_iteration: 125\n",
      "batch_iteration: 126\n",
      "batch_iteration: 127\n",
      "batch_iteration: 128\n",
      "batch_iteration: 129\n",
      "batch_iteration: 130\n",
      "batch_iteration: 131\n",
      "batch_iteration: 132\n",
      "batch_iteration: 133\n",
      "batch_iteration: 134\n",
      "batch_iteration: 135\n",
      "batch_iteration: 136\n",
      "batch_iteration: 137\n",
      "batch_iteration: 138\n",
      "batch_iteration: 139\n",
      "batch_iteration: 140\n",
      "batch_iteration: 141\n",
      "batch_iteration: 142\n",
      "batch_iteration: 143\n",
      "batch_iteration: 144\n",
      "batch_iteration: 145\n",
      "batch_iteration: 146\n",
      "batch_iteration: 147\n",
      "batch_iteration: 148\n",
      "batch_iteration: 149\n",
      "batch_iteration: 150\n",
      "batch_iteration: 151\n",
      "batch_iteration: 152\n",
      "batch_iteration: 153\n",
      "batch_iteration: 154\n",
      "batch_iteration: 155\n",
      "batch_iteration: 156\n",
      "batch_iteration: 157\n",
      "batch_iteration: 158\n",
      "batch_iteration: 159\n",
      "batch_iteration: 160\n",
      "batch_iteration: 161\n",
      "batch_iteration: 162\n",
      "batch_iteration: 163\n",
      "batch_iteration: 164\n",
      "batch_iteration: 165\n",
      "batch_iteration: 166\n",
      "batch_iteration: 167\n",
      "batch_iteration: 168\n",
      "batch_iteration: 169\n",
      "batch_iteration: 170\n",
      "batch_iteration: 171\n",
      "batch_iteration: 172\n",
      "batch_iteration: 173\n",
      "batch_iteration: 174\n",
      "batch_iteration: 175\n",
      "batch_iteration: 176\n",
      "batch_iteration: 177\n",
      "batch_iteration: 178\n",
      "batch_iteration: 179\n",
      "batch_iteration: 180\n",
      "batch_iteration: 181\n",
      "batch_iteration: 182\n",
      "batch_iteration: 183\n",
      "batch_iteration: 184\n",
      "batch_iteration: 185\n",
      "batch_iteration: 186\n",
      "batch_iteration: 187\n",
      "batch_iteration: 188\n",
      "batch_iteration: 189\n",
      "batch_iteration: 190\n",
      "batch_iteration: 191\n",
      "batch_iteration: 192\n",
      "batch_iteration: 193\n",
      "batch_iteration: 194\n",
      "batch_iteration: 195\n",
      "batch_iteration: 196\n",
      "batch_iteration: 197\n",
      "batch_iteration: 198\n",
      "batch_iteration: 199\n",
      "batch_iteration: 200\n",
      "batch_iteration: 201\n",
      "batch_iteration: 202\n",
      "batch_iteration: 203\n",
      "batch_iteration: 204\n",
      "batch_iteration: 205\n",
      "batch_iteration: 206\n",
      "batch_iteration: 207\n",
      "batch_iteration: 208\n",
      "batch_iteration: 209\n",
      "batch_iteration: 210\n",
      "batch_iteration: 211\n",
      "batch_iteration: 212\n",
      "batch_iteration: 213\n",
      "batch_iteration: 214\n",
      "batch_iteration: 215\n",
      "batch_iteration: 216\n",
      "batch_iteration: 217\n",
      "batch_iteration: 218\n",
      "batch_iteration: 219\n",
      "batch_iteration: 220\n",
      "batch_iteration: 221\n",
      "batch_iteration: 222\n",
      "batch_iteration: 223\n",
      "batch_iteration: 224\n",
      "batch_iteration: 225\n",
      "batch_iteration: 226\n",
      "batch_iteration: 227\n",
      "batch_iteration: 228\n",
      "batch_iteration: 229\n",
      "batch_iteration: 230\n",
      "batch_iteration: 231\n",
      "batch_iteration: 232\n",
      "batch_iteration: 233\n",
      "batch_iteration: 234\n",
      "batch_iteration: 235\n",
      "batch_iteration: 236\n",
      "batch_iteration: 237\n",
      "batch_iteration: 238\n",
      "batch_iteration: 239\n",
      "batch_iteration: 240\n",
      "batch_iteration: 241\n",
      "batch_iteration: 242\n",
      "batch_iteration: 243\n",
      "batch_iteration: 244\n",
      "batch_iteration: 245\n",
      "batch_iteration: 246\n",
      "batch_iteration: 247\n",
      "batch_iteration: 248\n",
      "batch_iteration: 249\n",
      "batch_iteration: 250\n",
      "batch_iteration: 251\n",
      "batch_iteration: 252\n",
      "batch_iteration: 253\n",
      "batch_iteration: 254\n",
      "batch_iteration: 255\n",
      "batch_iteration: 256\n",
      "batch_iteration: 257\n",
      "batch_iteration: 258\n",
      "batch_iteration: 259\n",
      "batch_iteration: 260\n",
      "batch_iteration: 261\n",
      "batch_iteration: 262\n",
      "batch_iteration: 263\n",
      "batch_iteration: 264\n",
      "batch_iteration: 265\n",
      "batch_iteration: 266\n",
      "batch_iteration: 267\n",
      "batch_iteration: 268\n",
      "batch_iteration: 269\n",
      "batch_iteration: 270\n",
      "batch_iteration: 271\n",
      "batch_iteration: 272\n",
      "batch_iteration: 273\n",
      "batch_iteration: 274\n",
      "batch_iteration: 275\n",
      "batch_iteration: 276\n",
      "batch_iteration: 277\n",
      "batch_iteration: 278\n",
      "batch_iteration: 279\n",
      "batch_iteration: 280\n",
      "batch_iteration: 281\n",
      "batch_iteration: 282\n",
      "batch_iteration: 283\n",
      "batch_iteration: 284\n",
      "batch_iteration: 285\n",
      "batch_iteration: 286\n",
      "batch_iteration: 287\n",
      "batch_iteration: 288\n",
      "batch_iteration: 289\n",
      "batch_iteration: 290\n",
      "batch_iteration: 291\n",
      "batch_iteration: 292\n",
      "batch_iteration: 293\n",
      "batch_iteration: 294\n",
      "batch_iteration: 295\n",
      "batch_iteration: 296\n",
      "batch_iteration: 297\n",
      "batch_iteration: 298\n",
      "batch_iteration: 299\n",
      "batch_iteration: 300\n",
      "batch_iteration: 301\n",
      "batch_iteration: 302\n",
      "batch_iteration: 303\n",
      "batch_iteration: 304\n",
      "batch_iteration: 305\n",
      "batch_iteration: 306\n",
      "batch_iteration: 307\n",
      "batch_iteration: 308\n",
      "batch_iteration: 309\n",
      "batch_iteration: 310\n",
      "batch_iteration: 311\n",
      "batch_iteration: 312\n",
      "batch_iteration: 313\n",
      "batch_iteration: 314\n",
      "batch_iteration: 315\n",
      "batch_iteration: 316\n",
      "batch_iteration: 317\n",
      "batch_iteration: 318\n",
      "batch_iteration: 319\n",
      "batch_iteration: 320\n",
      "batch_iteration: 321\n",
      "batch_iteration: 322\n",
      "batch_iteration: 323\n",
      "batch_iteration: 324\n",
      "batch_iteration: 325\n",
      "batch_iteration: 326\n",
      "batch_iteration: 327\n",
      "batch_iteration: 328\n",
      "batch_iteration: 329\n",
      "batch_iteration: 330\n",
      "batch_iteration: 331\n",
      "batch_iteration: 332\n",
      "batch_iteration: 333\n",
      "batch_iteration: 334\n",
      "batch_iteration: 335\n"
     ]
    }
   ],
   "source": [
    "restore_checkpoint = True\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"../../my_capsule_network\"\n",
    "\n",
    "#If run on AWS\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "config=config\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init_op.run()\n",
    "\n",
    "    total_batch = int(len(mnist.train.images)/batch_size)\n",
    "    total_batch_validation = int(len(mnist.validation.images)/batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
    "            a, c= sess.run([optimizer, margin_loss], feed_dict={X: batch_x, y: batch_y})\n",
    "            print('batch_iteration:', i)\n",
    "            avg_cost += c/total_batch\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost))\n",
    "        \n",
    "        acc_vals = []\n",
    "        for iterations in range(total_batch_validation):\n",
    "            batch_x, batch_y = mnist.validation.next_batch(batch_size=batch_size)\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: batch_x, y: batch_y})\n",
    "            acc_vals.append(val_acc)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print('val_acc:', acc_val)\n",
    "        \n",
    "        # And save the model if it improved:\n",
    "        if acc_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
