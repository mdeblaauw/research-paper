{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdeblaauw/anaconda3/envs/research-paper/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../../omniglot_images/train.pickle\n",
      "loading data from ../../omniglot_images/val.pickle\n",
      "loading data from ../../omniglot_images/test.pickle\n"
     ]
    }
   ],
   "source": [
    "path = '../../omniglot_images/'\n",
    "data_subsets = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "data = {}\n",
    "categories = {}\n",
    "info = {}\n",
    "        \n",
    "for name in data_subsets:\n",
    "    file_path = os.path.join(path, name + \".pickle\")\n",
    "    print(\"loading data from {}\".format(file_path))\n",
    "    with open(file_path,\"rb\") as f:\n",
    "        (X,c) = pickle.load(f)\n",
    "        data[name] = X\n",
    "        categories[name] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_data(size, s='train'):\n",
    "    #get train data and shape\n",
    "    X=data[s]\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    \n",
    "    #initialize 2 empty arrays for the input size in a list\n",
    "    pairs=[np.zeros((size, h, w,1)) for i in range(2)]\n",
    "    \n",
    "    #initialize vector for the targets\n",
    "    targets=np.zeros((size,1))\n",
    "    \n",
    "    for x in range(size):\n",
    "        #randomly sample one class (character)\n",
    "        category = rnd.choice(n_classes,1,replace=False)\n",
    "        #randomly sample one example from class (1-20 characters)\n",
    "        idx_1 = rnd.randint(0, n_examples)\n",
    "        pairs[0][x,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "        #randomly sample again one example from class and add last class with modulo\n",
    "        # ..to ensure not same class pairs are created\n",
    "        idx_2 = (idx_1 + rnd.randint(0, n_examples)) % n_examples\n",
    "        #pick images of different class for 1st half and same class for 2nd half\n",
    "        if x >= size // 2:\n",
    "            category_2 = category\n",
    "            targets[x] = 1\n",
    "        else: \n",
    "        #add a random number to the category modulo n classes to ensure 2nd image has\n",
    "        # ..different category\n",
    "            idx_2 = rnd.randint(0, n_examples) \n",
    "            category_2 = (category + rnd.randint(1,n_classes)) % n_classes\n",
    "            targets[x] = 0\n",
    "        pairs[1][x,:,:,:] = X[category_2,idx_2].reshape(w, h,1)\n",
    "        \n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, train_labels = create_train_data(10000)\n",
    "val_set, val_labels = create_train_data(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rnd.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rnd.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38951745"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "\n",
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#call this layer on list of two input tensors.\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(lr=0.00006, beta_1=0.9, beta_2=0.999)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(pred, true_val):\n",
    "    acc_bool = np.equal(np.round_(pred), true_val)\n",
    "    acc = np.mean(acc_bool.astype(int))\n",
    "    \n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just as fast as the Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "training\n",
      "Loss: 4.416229\n",
      "Batch: 0\n",
      "Loss: 4.35786\n",
      "Batch: 1\n",
      "Loss: 4.287537\n",
      "Batch: 2\n",
      "Loss: 4.216594\n",
      "Batch: 3\n",
      "Loss: 4.142154\n",
      "Batch: 4\n",
      "Loss: 4.067619\n",
      "Batch: 5\n",
      "Loss: 3.9931695\n",
      "Batch: 6\n",
      "Loss: 3.9210038\n",
      "Batch: 7\n",
      "Loss: 3.8525903\n",
      "Batch: 8\n",
      "Loss: 3.7894886\n",
      "Batch: 9\n",
      "Loss: 3.7329462\n",
      "Batch: 10\n",
      "Loss: 3.6829195\n",
      "Batch: 11\n",
      "Loss: 3.6387866\n",
      "Batch: 12\n",
      "Loss: 3.600032\n",
      "Batch: 13\n",
      "Loss: 3.5658648\n",
      "Batch: 14\n",
      "Loss: 3.53525\n",
      "Batch: 15\n",
      "Loss: 3.5072691\n",
      "Batch: 16\n",
      "Loss: 3.4812582\n",
      "Batch: 17\n",
      "Loss: 3.4566553\n",
      "Batch: 18\n",
      "Loss: 3.4330444\n",
      "Batch: 19\n",
      "Loss: 3.4101796\n",
      "Batch: 20\n",
      "Loss: 3.3878486\n",
      "Batch: 21\n",
      "Loss: 3.3658955\n",
      "Batch: 22\n",
      "Loss: 3.3442175\n",
      "Batch: 23\n",
      "Loss: 3.3227396\n",
      "Batch: 24\n",
      "Loss: 3.3014138\n",
      "Batch: 25\n",
      "Loss: 3.2802022\n",
      "Batch: 26\n",
      "Loss: 3.2590814\n",
      "Batch: 27\n",
      "Loss: 3.2380357\n",
      "Batch: 28\n",
      "Loss: 3.217055\n",
      "Batch: 29\n",
      "Loss: 3.1961517\n",
      "Batch: 30\n",
      "Loss: 3.1752927\n",
      "Batch: 31\n",
      "Loss: 3.1544974\n",
      "Batch: 32\n",
      "Loss: 3.1337705\n",
      "Batch: 33\n",
      "Loss: 3.1130958\n",
      "Batch: 34\n",
      "Loss: 3.0924904\n",
      "Batch: 35\n",
      "Loss: 3.071966\n",
      "Batch: 36\n",
      "Loss: 3.0514975\n",
      "Batch: 37\n",
      "Loss: 3.0311148\n",
      "Batch: 38\n",
      "Loss: 3.0108023\n",
      "Batch: 39\n",
      "Loss: 2.9905734\n",
      "Batch: 40\n",
      "Loss: 2.9704213\n",
      "Batch: 41\n",
      "Loss: 2.9503584\n",
      "Batch: 42\n",
      "Loss: 2.9303868\n",
      "Batch: 43\n",
      "Loss: 2.910505\n",
      "Batch: 44\n",
      "Loss: 2.8907127\n",
      "Batch: 45\n",
      "Loss: 2.8710165\n",
      "Batch: 46\n",
      "Loss: 2.8514073\n",
      "Batch: 47\n",
      "Loss: 2.8319032\n",
      "Batch: 48\n",
      "Loss: 2.8124924\n",
      "Batch: 49\n",
      "Loss: 2.7931888\n",
      "Batch: 50\n",
      "Loss: 2.7739787\n",
      "Batch: 51\n",
      "Loss: 2.7548733\n",
      "Batch: 52\n",
      "Loss: 2.7358775\n",
      "Batch: 53\n",
      "Loss: 2.7169807\n",
      "Batch: 54\n",
      "Loss: 2.698184\n",
      "Batch: 55\n",
      "Loss: 2.6794922\n",
      "Batch: 56\n",
      "Loss: 2.6609113\n",
      "Batch: 57\n",
      "Loss: 2.6424265\n",
      "Batch: 58\n",
      "Loss: 2.624063\n",
      "Batch: 59\n",
      "Loss: 2.605801\n",
      "Batch: 60\n",
      "Loss: 2.587643\n",
      "Batch: 61\n",
      "Loss: 2.5695934\n",
      "Batch: 62\n",
      "Loss: 2.5516489\n",
      "Batch: 63\n",
      "Loss: 2.5338101\n",
      "Batch: 64\n",
      "Loss: 2.5160806\n",
      "Batch: 65\n",
      "Loss: 2.4984589\n",
      "Batch: 66\n",
      "Loss: 2.48094\n",
      "Batch: 67\n",
      "Loss: 2.4635363\n",
      "Batch: 68\n",
      "Loss: 2.4462392\n",
      "Batch: 69\n",
      "Loss: 2.4290447\n",
      "Batch: 70\n",
      "Loss: 2.4119601\n",
      "Batch: 71\n",
      "Loss: 2.394979\n",
      "Batch: 72\n",
      "Loss: 2.378114\n",
      "Batch: 73\n",
      "Loss: 2.361345\n",
      "Batch: 74\n",
      "Loss: 2.344688\n",
      "Batch: 75\n",
      "Loss: 2.3281338\n",
      "Batch: 76\n",
      "Loss: 2.3116798\n",
      "Batch: 77\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3000,1) (128,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-43c411df1375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mbatch_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mval_batch_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batch_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batch_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8647e7f291fe>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(pred, true_val)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0macc_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_bool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3000,1) (128,1) "
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "print(\"!\")\n",
    "batch_size = 128\n",
    "total_batch = int(10000/batch_size)\n",
    "total_batch_val = int(3000/batch_size)\n",
    "epoch = 10\n",
    "\n",
    "print(\"training\")\n",
    "for i in range(epoch):\n",
    "    batch_x1, batch_x2, batch_y = shuffle(train_set[0],train_set[1], train_labels, n_samples = batch_size)\n",
    "    train_batch_acc = 0\n",
    "    for j in range(total_batch):\n",
    "        loss=siamese_net.train_on_batch([batch_x1, batch_x2],batch_y)\n",
    "        probs = siamese_net.predict([batch_x1, batch_x2])\n",
    "        train_batch_acc =+ accuracy(probs, batch_y)\n",
    "        print('Loss:', loss)\n",
    "        print('Batch:', j)\n",
    "    train_acc = train_batch_acc/total_batch\n",
    "    val_batch_acc = 0\n",
    "    for validation in range(total_batch_val):\n",
    "        batch_x1, batch_x2, batch_y = shuffle(val_set[0],val_set[1], val_labels, n_samples = batch_size)\n",
    "        probs = siamese_net.predict([batch_x1, batch_x2])\n",
    "        val_batch_acc =+ accuracy(probs, batch_y)\n",
    "    val_acc = val_batch_acc/total_batch_val\n",
    "    print('Train accuracy:', train_acc)\n",
    "    print('Validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research-paper]",
   "language": "python",
   "name": "conda-env-research-paper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
