{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdeblaauw/anaconda3/envs/research-paper/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "data_subsets = ['train', 'val']\n",
    "data = {}\n",
    "\n",
    "for name in data_subsets:\n",
    "    with BytesIO() as files:\n",
    "        path = \"omniglot_images/\" +name+ \".pickle\"\n",
    "        s3.Bucket(\"research-paper-omniglot-data\").download_fileobj(path, files)\n",
    "        files.seek(0)    # move back to the beginning after writing\n",
    "        (X,c) = pickle.load(files)\n",
    "        data[name] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_data(size, s='train'):\n",
    "    #get train data and shape\n",
    "    X=data[s]\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    \n",
    "    #initialize 2 empty arrays for the input size in a list\n",
    "    pairs=[np.zeros((size, h, w,1)) for i in range(2)]\n",
    "    \n",
    "    #initialize vector for the targets\n",
    "    targets=np.zeros((size,1))\n",
    "    \n",
    "    for x in range(size):\n",
    "        #randomly sample one class (character)\n",
    "        category = rnd.choice(n_classes,1,replace=False)\n",
    "        #randomly sample one example from class (1-20 characters)\n",
    "        idx_1 = rnd.randint(0, n_examples)\n",
    "        pairs[0][x,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "        #randomly sample again one example from class and add last class with modulo\n",
    "        # ..to ensure not same class pairs are created\n",
    "        idx_2 = (idx_1 + rnd.randint(0, n_examples)) % n_examples\n",
    "        #pick images of different class for 1st half and same class for 2nd half\n",
    "        if x >= size // 2:\n",
    "            category_2 = category\n",
    "            targets[x] = 1\n",
    "        else: \n",
    "        #add a random number to the category modulo n classes to ensure 2nd image has\n",
    "        # ..different category\n",
    "            idx_2 = rnd.randint(0, n_examples) \n",
    "            category_2 = (category + rnd.randint(1,n_classes)) % n_classes\n",
    "            targets[x] = 0\n",
    "        pairs[1][x,:,:,:] = X[category_2,idx_2].reshape(w, h,1)\n",
    "        \n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, train_labels = create_train_data(10000)\n",
    "#val_set, val_labels = create_train_data(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rnd.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rnd.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38951745"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "\n",
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#call this layer on list of two input tensors.\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_oneshot_set(N_way, s='val'):\n",
    "    N = N_way\n",
    "    X=data[s]\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    indices = rnd.randint(0,n_examples,size=(N,))\n",
    "    #Get mutually exclusive classes (characters) from test set\n",
    "    categories = rnd.choice(range(n_classes),size=(N,),replace=False)\n",
    "    #Set true image as first indice from chosen classes\n",
    "    true_category = categories[0]\n",
    "    #Generate 2 character places for true image\n",
    "    ex1, ex2 = rnd.choice(n_examples,replace=False,size=(2,))\n",
    "    #Pick test image with true image indice class and one character indice.\n",
    "    # ..multipli array in N_way\n",
    "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
    "    #Select N_way set from test set with class and character indices\n",
    "    support_set = X[categories,indices,:,:]\n",
    "    #Set first indice as true image, but with ex2 character\n",
    "    # ..this is to make sure both true images are not the same character\n",
    "    support_set[0,:,:] = X[true_category,ex2]\n",
    "    support_set = support_set.reshape(N, w, h,1)\n",
    "    targets = np.zeros((N,1))\n",
    "    targets[0] = 1\n",
    "    #Shuffle \n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image,support_set]\n",
    "\n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just as fast as the Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "training\n",
      "4.477033\n",
      "4.4507694\n",
      "4.4203677\n",
      "4.336025\n",
      "4.406959\n",
      "4.409644\n",
      "4.3640656\n",
      "4.328512\n",
      "4.2900486\n",
      "4.2983346\n",
      "4.2273464\n",
      "4.192971\n",
      "4.3058133\n",
      "4.231699\n",
      "4.1825423\n",
      "4.117877\n",
      "4.138963\n",
      "4.1701436\n",
      "4.055266\n",
      "4.125528\n",
      "4.0429964\n",
      "4.1633415\n",
      "4.0988526\n",
      "3.9130354\n",
      "3.9574254\n",
      "3.9353437\n",
      "4.0561857\n",
      "3.9013896\n",
      "3.989008\n",
      "3.9800484\n",
      "3.9776433\n",
      "3.9561262\n",
      "3.8391397\n",
      "3.888539\n",
      "3.891987\n",
      "3.7954285\n",
      "3.7833607\n",
      "3.6233182\n",
      "3.933909\n",
      "3.7771113\n",
      "3.662622\n",
      "3.7421434\n",
      "3.698161\n",
      "3.826476\n",
      "3.7079792\n",
      "3.5754511\n",
      "3.6507468\n",
      "3.6574306\n",
      "3.6180186\n",
      "3.5716555\n",
      "3.6959076\n",
      "3.5625272\n",
      "3.6259234\n",
      "3.5809731\n",
      "3.5915716\n",
      "3.5915072\n",
      "3.4851267\n",
      "3.55404\n",
      "3.6924386\n",
      "3.5039399\n",
      "3.4844913\n",
      "3.5576663\n",
      "3.3429768\n",
      "3.323157\n",
      "3.294463\n",
      "3.496505\n",
      "3.4653265\n",
      "3.3445127\n",
      "3.3578994\n",
      "3.3760676\n",
      "3.4354784\n",
      "3.3104932\n",
      "3.390839\n",
      "3.3968585\n",
      "3.3343697\n",
      "3.1506033\n",
      "3.2285235\n",
      "3.3289552\n",
      "3.2846923\n",
      "3.192156\n",
      "3.2947872\n",
      "3.2192504\n",
      "3.429077\n",
      "3.3118815\n",
      "3.2904418\n",
      "3.0818505\n",
      "3.2358675\n",
      "3.1899366\n",
      "3.1842031\n",
      "3.1727242\n",
      "3.2092698\n",
      "3.1484346\n",
      "3.049654\n",
      "3.1250887\n",
      "3.0225902\n",
      "3.212165\n",
      "3.1562216\n",
      "3.083269\n",
      "2.9416423\n",
      "3.1956544\n",
      "3.3154624\n",
      "3.2382147\n",
      "3.0951135\n",
      "2.996202\n",
      "3.219486\n",
      "3.157845\n",
      "3.16383\n",
      "2.9717553\n",
      "3.0652819\n",
      "3.0617723\n",
      "3.0495412\n",
      "2.957685\n",
      "3.0544338\n",
      "2.8932264\n",
      "2.9323502\n",
      "2.899681\n",
      "2.9929993\n",
      "3.0628965\n",
      "2.8321116\n",
      "2.9634635\n",
      "2.973231\n",
      "2.8382468\n",
      "2.8970475\n",
      "2.8600574\n",
      "2.9466286\n",
      "2.9315693\n",
      "3.0288079\n",
      "2.7134843\n",
      "2.918177\n",
      "2.8798063\n",
      "2.8928525\n",
      "2.887631\n",
      "2.96846\n",
      "2.7391176\n",
      "2.8195791\n",
      "2.7880757\n",
      "2.8164442\n",
      "2.8727033\n",
      "2.8145382\n",
      "2.6930356\n",
      "2.684029\n",
      "2.742254\n",
      "2.6647902\n",
      "2.7480497\n",
      "2.7026367\n",
      "2.7704458\n",
      "2.638749\n",
      "2.725085\n",
      "2.5361607\n",
      "2.6940212\n",
      "2.701821\n",
      "2.6785996\n",
      "2.5969534\n",
      "2.7660432\n",
      "2.7635796\n",
      "2.6513095\n",
      "2.6454914\n",
      "2.5065622\n",
      "2.6308072\n",
      "2.8088539\n",
      "2.6757884\n",
      "2.6557572\n",
      "2.5834742\n",
      "2.5835958\n",
      "2.6718314\n",
      "2.532501\n",
      "2.6720774\n",
      "2.524852\n",
      "2.6535106\n",
      "2.543587\n",
      "2.5855973\n",
      "2.5396786\n",
      "2.5286148\n",
      "2.4851544\n",
      "2.4977944\n",
      "2.5358374\n",
      "2.3872952\n",
      "2.6039402\n",
      "2.4928868\n",
      "2.5284734\n",
      "2.526399\n",
      "2.4083173\n",
      "2.5435512\n",
      "2.5368135\n",
      "2.5939198\n",
      "2.4833384\n",
      "2.48757\n",
      "2.4685333\n",
      "2.4401822\n",
      "2.5169582\n",
      "2.4150255\n",
      "2.40369\n",
      "2.4438741\n",
      "2.346158\n",
      "2.4533687\n",
      "2.4108667\n",
      "2.4222858\n",
      "2.372789\n",
      "2.3292158\n",
      "2.4001713\n",
      "2.447851\n",
      "2.3359158\n",
      "2.3940988\n",
      "2.5006945\n",
      "2.3575993\n",
      "2.7491057\n",
      "2.3953707\n",
      "2.3887112\n",
      "2.3313289\n",
      "2.44044\n",
      "2.49388\n",
      "2.5266156\n",
      "2.2624922\n",
      "2.298368\n",
      "2.327028\n",
      "2.188859\n",
      "2.4355376\n",
      "2.4730031\n",
      "2.4024863\n",
      "2.207457\n",
      "2.319688\n",
      "2.3442025\n",
      "2.4578588\n",
      "2.2608414\n",
      "2.2965765\n",
      "2.4489625\n",
      "2.3633945\n",
      "2.3058622\n",
      "2.2774382\n",
      "2.206698\n",
      "2.3692923\n",
      "2.2509031\n",
      "2.1443396\n",
      "2.2857904\n",
      "2.2140641\n",
      "2.2223408\n",
      "2.2235446\n",
      "2.3615878\n",
      "2.3508186\n",
      "2.103892\n",
      "2.1550002\n",
      "2.1759565\n",
      "2.1685069\n",
      "2.138546\n",
      "2.1531146\n",
      "2.189451\n",
      "2.1437824\n",
      "2.2726724\n",
      "2.2114842\n",
      "2.1228535\n",
      "2.3096325\n",
      "2.1903887\n",
      "2.199102\n",
      "2.513916\n",
      "2.1911795\n",
      "2.2052891\n",
      "2.2506602\n",
      "2.3103752\n",
      "2.2777748\n",
      "2.1780136\n",
      "2.168401\n",
      "2.1878679\n",
      "2.2704542\n",
      "2.1177435\n",
      "2.0527916\n",
      "2.195652\n",
      "2.1851857\n",
      "2.173199\n",
      "2.2246814\n",
      "2.1173518\n",
      "2.0431645\n",
      "2.2280002\n",
      "2.0995839\n",
      "2.1996982\n",
      "2.1387842\n",
      "2.1691723\n",
      "2.1091957\n",
      "2.0966253\n",
      "2.115918\n",
      "2.1372292\n",
      "2.1585927\n",
      "2.1274192\n",
      "2.096579\n",
      "1.9963084\n",
      "2.0190258\n",
      "2.179223\n",
      "2.0629365\n",
      "2.206201\n",
      "1.988804\n",
      "2.0280619\n",
      "2.0679164\n",
      "1.9342138\n",
      "2.1073704\n",
      "1.9972143\n",
      "2.039162\n",
      "2.008568\n",
      "1.9827312\n",
      "1.8925372\n",
      "2.0321372\n",
      "2.0651152\n",
      "1.9081314\n",
      "2.0441935\n",
      "2.0345895\n",
      "2.0878491\n",
      "2.0747519\n",
      "1.9878405\n",
      "2.0169017\n",
      "2.0473638\n",
      "2.029793\n",
      "1.8730248\n",
      "2.0435066\n",
      "2.0477192\n",
      "evaluating\n",
      "Validation accuracy: 0.272\n",
      "1.9041088\n",
      "1.9706848\n",
      "2.0017333\n",
      "1.9407723\n",
      "1.8619463\n",
      "1.8117034\n",
      "1.9717641\n",
      "1.9268254\n",
      "1.8741004\n",
      "1.9173117\n",
      "2.060567\n",
      "1.9771272\n",
      "1.8963108\n",
      "1.8912657\n",
      "2.1231897\n",
      "1.9870567\n",
      "1.8759366\n",
      "1.8852983\n",
      "1.9663491\n",
      "1.9312197\n",
      "1.9025104\n",
      "1.8744378\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7f8a5001b087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "print(\"!\")\n",
    "evaluate_every = 50 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 90000\n",
    "N_way = 20 # how many classes for testing one-shot tasks>\n",
    "n_val = 250 #how mahy one-shot tasks to validate on?\n",
    "\n",
    "print(\"training\")\n",
    "for i in range(1, n_iter):\n",
    "    batch_x1, batch_x2, batch_y = shuffle(train_set[0],train_set[1], train_labels, n_samples = batch_size)\n",
    "    loss=siamese_net.train_on_batch([batch_x1, batch_x2],batch_y)\n",
    "    print('batch iteration:', i)\n",
    "    print('loss:'loss)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"evaluating\")\n",
    "        n_correct = 0\n",
    "        for j in range(n_val):\n",
    "            pairs, labels = generate_oneshot_set(N_way, s='val')\n",
    "            probs = siamese_net.predict(pairs)\n",
    "            if np.argmax(probs) == np.argmax(labels):\n",
    "                    n_correct+=1\n",
    "        percent_correct = (n_correct / n_val)\n",
    "        print('Validation accuracy:', percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research-paper]",
   "language": "python",
   "name": "conda-env-research-paper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
