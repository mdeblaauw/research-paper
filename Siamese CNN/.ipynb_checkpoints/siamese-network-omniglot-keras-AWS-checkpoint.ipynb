{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdeblaauw/anaconda3/envs/research-paper/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rnd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "data_subsets = ['train', 'val']\n",
    "data = {}\n",
    "\n",
    "for name in data_subsets:\n",
    "    with BytesIO() as files:\n",
    "        path = \"omniglot_images/\" +name+ \".pickle\"\n",
    "        s3.Bucket(\"research-paper-omniglot-data\").download_fileobj(path, files)\n",
    "        files.seek(0)    # move back to the beginning after writing\n",
    "        (X,c) = pickle.load(files)\n",
    "        data[name] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../../omniglot_images/train.pickle\n",
      "loading data from ../../omniglot_images/val.pickle\n",
      "loading data from ../../omniglot_images/test.pickle\n"
     ]
    }
   ],
   "source": [
    "path = '../../omniglot_images/'\n",
    "data_subsets = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "data = {}\n",
    "categories = {}\n",
    "info = {}\n",
    "        \n",
    "for name in data_subsets:\n",
    "    file_path = os.path.join(path, name + \".pickle\")\n",
    "    print(\"loading data from {}\".format(file_path))\n",
    "    with open(file_path,\"rb\") as f:\n",
    "        (X,c) = pickle.load(f)\n",
    "        data[name] = X\n",
    "        categories[name] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(size, s='train'):\n",
    "    #get train data and shape\n",
    "    X=data[s]\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    \n",
    "    #initialize 2 empty arrays for the input size in a list\n",
    "    pairs=[np.zeros((size, h, w,1)) for i in range(2)]\n",
    "    \n",
    "    #initialize vector for the targets\n",
    "    targets=np.zeros((size,1))\n",
    "    \n",
    "    for x in range(size):\n",
    "        #randomly sample one class (character)\n",
    "        category = rnd.choice(n_classes,1,replace=False)\n",
    "        #randomly sample one example from class (1-20 characters)\n",
    "        idx_1 = rnd.randint(0, n_examples)\n",
    "        pairs[0][x,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "        #randomly sample again one example from class and add last class with modulo\n",
    "        # ..to ensure not same class pairs are created\n",
    "        idx_2 = (idx_1 + rnd.randint(0, n_examples)) % n_examples\n",
    "        #pick images of different class for 1st half and same class for 2nd half\n",
    "        if x >= size // 2:\n",
    "            category_2 = category\n",
    "            targets[x] = 1\n",
    "        else: \n",
    "        #add a random number to the category modulo n classes to ensure 2nd image has\n",
    "        # ..different category\n",
    "            idx_2 = rnd.randint(0, n_examples) \n",
    "            category_2 = (category + rnd.randint(1,n_classes)) % n_classes\n",
    "            targets[x] = 0\n",
    "        pairs[1][x,:,:,:] = X[category_2,idx_2].reshape(w, h,1)\n",
    "        \n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, train_labels = create_train_data(10000)\n",
    "#val_set, val_labels = create_train_data(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rnd.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rnd.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38951745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "\n",
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#call this layer on list of two input tensors.\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_oneshot_set(N, s='val'):\n",
    "    \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "    X=data[s]\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    indices = rnd.randint(0,n_examples,size=(N,))\n",
    "    categories = rnd.choice(range(n_classes),size=(N,),replace=False)            \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = rnd.choice(n_examples,replace=False,size=(2,))\n",
    "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
    "    support_set = X[categories,indices,:,:]\n",
    "    support_set[0,:,:] = X[true_category,ex2]\n",
    "    support_set = support_set.reshape(N, w, h,1)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image,support_set]\n",
    "\n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(probs, labels):\n",
    "    probs_rounded = np.round_(probs)\n",
    "    output = np.equal(probs_rounded, labels)\n",
    "    accuracy = np.mean(output.astype(int))\n",
    "    \n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just as fast as the Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "training\n",
      "[[0.59860855]\n",
      " [0.60151666]\n",
      " [0.5986695 ]\n",
      " [0.59037036]\n",
      " [0.5949767 ]\n",
      " [0.6027443 ]\n",
      " [0.5972136 ]\n",
      " [0.60840464]\n",
      " [0.6077078 ]\n",
      " [0.59073865]]\n",
      "acc train: 0.5\n",
      "acc val: 0.5\n",
      "batch iteration: 5\n",
      "loss: 3.7665472\n",
      "[[0.58856386]\n",
      " [0.5816251 ]\n",
      " [0.5776235 ]\n",
      " [0.58460945]\n",
      " [0.58603245]\n",
      " [0.5835401 ]\n",
      " [0.5776499 ]\n",
      " [0.6071753 ]\n",
      " [0.5736838 ]\n",
      " [0.59426856]]\n",
      "acc train: 0.5\n",
      "acc val: 0.5\n",
      "batch iteration: 10\n",
      "loss: 3.6625943\n",
      "[[0.5825362 ]\n",
      " [0.5691729 ]\n",
      " [0.58990264]\n",
      " [0.5927188 ]\n",
      " [0.5747932 ]\n",
      " [0.6015618 ]\n",
      " [0.5841539 ]\n",
      " [0.6007903 ]\n",
      " [0.5909332 ]\n",
      " [0.6033505 ]]\n",
      "acc train: 0.5\n",
      "acc val: 0.5\n",
      "batch iteration: 15\n",
      "loss: 3.5870743\n",
      "[[0.56600064]\n",
      " [0.56839687]\n",
      " [0.57659674]\n",
      " [0.58280677]\n",
      " [0.5829316 ]\n",
      " [0.5869292 ]\n",
      " [0.5757913 ]\n",
      " [0.5854396 ]\n",
      " [0.6232173 ]\n",
      " [0.58542544]]\n",
      "acc train: 0.5\n",
      "acc val: 0.5\n",
      "batch iteration: 20\n",
      "loss: 3.4927566\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-e86522fa1c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#loss=siamese_net.train_on_batch([batch_x1, batch_x2],batch_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msiamese_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research-paper/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "print(\"!\")\n",
    "evaluate_every = 5 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 90000\n",
    "N_way = 20 # how many classes for testing one-shot tasks>\n",
    "n_val = 250 #how mahy one-shot tasks to validate on?\n",
    "\n",
    "print(\"training\")\n",
    "for i in range(1, n_iter):\n",
    "    #batch_x1, batch_x2, batch_y = shuffle(train_set[0],train_set[1], train_labels, n_samples = batch_size)\n",
    "    #loss=siamese_net.train_on_batch([batch_x1, batch_x2],batch_y)\n",
    "    batch_x, batch_y = create_train_data(batch_size)\n",
    "    loss=siamese_net.train_on_batch(batch_x,batch_y)\n",
    "    if i % evaluate_every == 0:\n",
    "        train_x, train_y = create_train_data(10)\n",
    "        val_x, val_y = create_train_data(10, s='val')\n",
    "        prob_train = siamese_net.predict(train_x)\n",
    "        prob_val = siamese_net.predict(val_x)\n",
    "        print(prob_train)\n",
    "        acc_train = prediction(prob_train, train_y)\n",
    "        acc_val = prediction(prob_val, val_y)\n",
    "        \n",
    "        print('acc train:', acc_train)\n",
    "        print('acc val:', acc_val)\n",
    "        print('batch iteration:', i)\n",
    "        print('loss:', loss)\n",
    "        #print(\"evaluating\")\n",
    "        #n_correct = 0\n",
    "        #for j in range(n_val):\n",
    "            #pairs, labels = generate_oneshot_set(N_way, s='val')\n",
    "            #probs = siamese_net.predict(pairs)\n",
    "            #if np.argmax(probs) == np.argmax(labels):\n",
    "                    #n_correct+=1\n",
    "        #percent_correct = (n_correct / n_val)\n",
    "        #print('Validation accuracy:', percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round_([0.1,0.3,0.51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch, label = get_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch, label = create_train_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 105, 105, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first = batch[0].reshape(10,105,105)\n",
    "second = batch[1].reshape(10,105,105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10763ae10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair = 9\n",
    "fig,(ax1,ax2) = plt.subplots(2)\n",
    "ax1.matshow(first[pair],cmap='gray')\n",
    "ax2.matshow(second[pair],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(964, 20, 105, 105)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research-paper]",
   "language": "python",
   "name": "conda-env-research-paper-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
